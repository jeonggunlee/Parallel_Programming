{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_googleDrive_CUDAExam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonggunlee/CUDATeaching/blob/master/02_cuda_lab/00_googleDrive_CUDAExam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGw2-232b3CN",
        "colab_type": "text"
      },
      "source": [
        "## Google Drive를 활용한 CUDA 프로그래밍\n",
        "\n",
        "직접 Google Drive에서 프로그램을 수행할 수 있습니다. \n",
        "\n",
        "이경우 mount가 필요하고 **여러개**의 화일로 이루어진 코드들을 수행할 수 있습니다.\n",
        "\n",
        "또한 직접 구글 드라이브로 **git clone** 하여 소스를 살펴보고 실 데이터와 함께 수행 시킬 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwt6hjvawgy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VALOy7EMcp4V",
        "colab_type": "text"
      },
      "source": [
        "Enter your authorization code:\n",
        "\n",
        "지정된 URL을 클릭하면 인증 코드를 볼수 있으며, 이를 복사하여 입력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfuMBZhrwkEz",
        "colab_type": "code",
        "outputId": "33c3232e-4d90-421b-e3b3-a2eebb0ab026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4SIRCeAxuZ6",
        "colab_type": "code",
        "outputId": "fc8386b9-9898-41bf-fcef-72301735094e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T7r6E_wx7sb",
        "colab_type": "code",
        "outputId": "ab56884b-16ac-471a-a1a2-30ef6a10e31e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgJG8sc5x8b6",
        "colab_type": "code",
        "outputId": "ac3478bc-0def-40c1-dccb-b0b3741031e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd gdrive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOks_A0px-gL",
        "colab_type": "code",
        "outputId": "5fa8d67e-95c2-44bc-a62d-73920223de6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'My Drive'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJmG1Mhpx_dj",
        "colab_type": "code",
        "outputId": "e46a2164-741d-4a56-f0ec-1e9b6b2a80e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd My Drive"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGIKG8rZu7oI",
        "colab_type": "code",
        "outputId": "c333ac1d-e86b-4dc5-be79-67db71f40799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd GPUCoding"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/GPUCoding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Coj2G4vInx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2a08cd4-36e9-466b-950d-319a48de803b"
      },
      "source": [
        "!ls "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cs344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbUl1rt8vKMR",
        "colab_type": "code",
        "outputId": "261caf8d-3661-4b2a-bb08-28cd59ac8606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "!git clone https://github.com/jeonggunlee/cs344/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cs344'...\n",
            "remote: Enumerating objects: 726, done.\u001b[K\n",
            "remote: Total 726 (delta 0), reused 0 (delta 0), pack-reused 726\u001b[K\n",
            "Receiving objects: 100% (726/726), 66.62 MiB | 21.37 MiB/s, done.\n",
            "Resolving deltas: 100% (402/402), done.\n",
            "Checking out files: 100% (135/135), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oVc2hwWv6fm",
        "colab_type": "code",
        "outputId": "c249060d-58b6-4a9f-8cd0-6b9f1d9369f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cs344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zev0VeK1v9We",
        "colab_type": "code",
        "outputId": "878ec962-78ef-47d9-d519-91361b8cdf82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd cs344"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/GPUCoding/cs344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPQEVuOJv_Sh",
        "colab_type": "code",
        "outputId": "d7dc28d5-91ca-4136-f684-50340bfd7640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " CMakeLists.txt\t\t'Lesson Slides'  'Student Contributions'\n",
            " Final\t\t\t'Problem Sets'\n",
            "'Lesson Code Snippets'\t README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvBCLNohv_6a",
        "colab_type": "code",
        "outputId": "650ef06a-5f7a-4b39-e2f3-4df13d90e34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd 'Lesson Code Snippets'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/GPUCoding/cs344/Lesson Code Snippets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG_GoCgFwFzU",
        "colab_type": "code",
        "outputId": "cda80f7e-5abd-4aa6-ed29-ee3a85cb5b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Lesson 2 Code Snippets'  'Lesson 5 Code Snippets'\n",
            "'Lesson 3 Code Snippets'  'Lesson 7 Code Snippets'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9ycqer9wG9H",
        "colab_type": "code",
        "outputId": "16c0bf09-e04e-43d1-c034-5c74c27ad9ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd 'Lesson 2 Code Snippets'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/GPUCoding/cs344/Lesson Code Snippets/Lesson 2 Code Snippets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdx17gLKwKg_",
        "colab_type": "code",
        "outputId": "2b6b471b-0b79-4223-f57d-73f8f7a796f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "associative\tatomics     gputimer.h\t       hello_threadIdx\t   memory\n",
            "associative.cu\tatomics.cu  hello_blockIdx.cu  hello_threadIdx.cu  memory.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd8xFyNgwOZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc -o hello_threadIdx hello_threadIdx.cu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKTA6N7OwWLP",
        "colab_type": "code",
        "outputId": "b8db4c37-de26-4dcd-f486-de2b990360bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!./hello_threadIdx"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello world! I'm thread 0\n",
            "Hello world! I'm thread 1\n",
            "Hello world! I'm thread 2\n",
            "Hello world! I'm thread 3\n",
            "That's all!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuKwN4qtwY8j",
        "colab_type": "code",
        "outputId": "817eb49a-44b5-408a-eafa-6a80bd25adb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "associative\tatomics     gputimer.h\t       hello_threadIdx\t   memory\n",
            "associative.cu\tatomics.cu  hello_blockIdx.cu  hello_threadIdx.cu  memory.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iRMvEUOwcMI",
        "colab_type": "code",
        "outputId": "0b0c4f5e-666e-4ca1-de32-d50aaa1a06b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "!cat hello_threadIdx.cu"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#include <stdio.h>\n",
            "\n",
            "#define NUM_BLOCKS 1\n",
            "#define BLOCK_WIDTH 4\n",
            "\n",
            "__global__ void hello()\n",
            "{\n",
            "    printf(\"Hello world! I'm thread %d\\n\", threadIdx.x);\n",
            "}\n",
            "\n",
            "\n",
            "int main(int argc,char **argv)\n",
            "{\n",
            "    // launch the kernel\n",
            "    hello<<<NUM_BLOCKS, BLOCK_WIDTH>>>();\n",
            "\n",
            "    // force the printf()s to flush\n",
            "    cudaDeviceSynchronize();\n",
            "\n",
            "    printf(\"That's all!\\n\");\n",
            "\n",
            "    return 0;\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1I7ipYIeEBE",
        "colab_type": "text"
      },
      "source": [
        "### 위의 코드는 다음과 같습니다.\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "\n",
        "// block의 수 정의\n",
        "#define NUM_BLOCKS 1\n",
        "// block 내부의 thread 수 정의\n",
        "#define BLOCK_WIDTH 4\n",
        "\n",
        "__global__ void hello()\n",
        "{\n",
        "    printf(\"Hello world! I'm thread %d\\n\", threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(int argc,char **argv)\n",
        "{\n",
        "    // launch the kernel\n",
        "    hello<<<NUM_BLOCKS, BLOCK_WIDTH>>>();\n",
        "\n",
        "// force the printf()s to flush\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    printf(\"That's all!\\n\");\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RciMtJV7wgBd",
        "colab_type": "code",
        "outputId": "3a7624a9-f674-42d1-a94f-a61877d6f855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "associative\tatomics     gputimer.h\t       hello_threadIdx\t   memory\n",
            "associative.cu\tatomics.cu  hello_blockIdx.cu  hello_threadIdx.cu  memory.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmJGXivkwlqg",
        "colab_type": "code",
        "outputId": "75783464-cd61-463e-ce68-99273d192230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!nvcc -o memory memory.cu"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "memory.cu(11): warning: variable \"f\" was set but never used\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67oeJh6Mes4M",
        "colab_type": "text"
      },
      "source": [
        "### memory.cu의 내부는 다음과 같습니다.\n",
        "\n",
        "다양한 메모리 형태에 대한 사용방법을 내재하고 있습니다.\n",
        "\n",
        "- local memory\n",
        "- global memory\n",
        "- shared memory\n",
        "\n",
        "\n",
        "```c\n",
        "// Using different memory spaces in CUDA\n",
        "#include <stdio.h>\n",
        "\n",
        "/**********************\n",
        " * using local memory *\n",
        " **********************/\n",
        "\n",
        "// a __device__ or __global__ function runs on the GPU\n",
        "__global__ void use_local_memory_GPU(float in)\n",
        "{\n",
        "    float f;    // variable \"f\" is in local memory and private to each thread\n",
        "    f = in;     // parameter \"in\" is in local memory and private to each thread\n",
        "    // ... real code would presumably do other stuff here ... \n",
        "}\n",
        "\n",
        "/**********************\n",
        " * using global memory *\n",
        " **********************/\n",
        "\n",
        "// a __global__ function runs on the GPU & can be called from host\n",
        "__global__ void use_global_memory_GPU(float *array)\n",
        "{\n",
        "    // \"array\" is a pointer into global memory on the device\n",
        "    array[threadIdx.x] = 2.0f * (float) threadIdx.x;\n",
        "}\n",
        "\n",
        "/**********************\n",
        " * using shared memory *\n",
        " **********************/\n",
        "\n",
        "// (for clarity, hardcoding 128 threads/elements and omitting out-of-bounds checks)\n",
        "__global__ void use_shared_memory_GPU(float *array)\n",
        "{\n",
        "    // local variables, private to each thread\n",
        "    int i, index = threadIdx.x;\n",
        "    float average, sum = 0.0f;\n",
        "\n",
        "    // __shared__ variables are visible to all threads in the thread block\n",
        "    // and have the same lifetime as the thread block\n",
        "    __shared__ float sh_arr[128];\n",
        "\n",
        "    // copy data from \"array\" in global memory to sh_arr in shared memory.\n",
        "    // here, each thread is responsible for copying a single element.\n",
        "    sh_arr[index] = array[index];\n",
        "\n",
        "    __syncthreads();    // ensure all the writes to shared memory have completed\n",
        "\n",
        "    // now, sh_arr is fully populated. Let's find the average of all previous elements\n",
        "    for (i=0; i<index; i++) { sum += sh_arr[i]; }\n",
        "    average = sum / (index + 1.0f);\n",
        "\n",
        "    // if array[index] is greater than the average of array[0..index-1], replace with average.\n",
        "    // since array[] is in global memory, this change will be seen by the host (and potentially \n",
        "    // other thread blocks, if any)\n",
        "    if (array[index] > average) { array[index] = average; }\n",
        "\n",
        "    // the following code has NO EFFECT: it modifies shared memory, but \n",
        "    // the resulting modified data is never copied back to global memory\n",
        "    // and vanishes when the thread block completes\n",
        "    sh_arr[index] = 3.14;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    /*\n",
        "     * First, call a kernel that shows using local memory \n",
        "     */\n",
        "    use_local_memory_GPU<<<1, 128>>>(2.0f);\n",
        "\n",
        "    /*\n",
        "     * Next, call a kernel that shows using global memory\n",
        "     */\n",
        "    float h_arr[128];   // convention: h_ variables live on host\n",
        "    float *d_arr;       // convention: d_ variables live on device (GPU global mem)\n",
        "\n",
        "    // allocate global memory on the device, place result in \"d_arr\"\n",
        "    cudaMalloc((void **) &d_arr, sizeof(float) * 128);\n",
        "    // now copy data from host memory \"h_arr\" to device memory \"d_arr\"\n",
        "    cudaMemcpy((void *)d_arr, (void *)h_arr, sizeof(float) * 128, cudaMemcpyHostToDevice);\n",
        "    // launch the kernel (1 block of 128 threads)\n",
        "    use_global_memory_GPU<<<1, 128>>>(d_arr);  // modifies the contents of array at d_arr\n",
        "    // copy the modified array back to the host, overwriting contents of h_arr\n",
        "    cudaMemcpy((void *)h_arr, (void *)d_arr, sizeof(float) * 128, cudaMemcpyDeviceToHost);\n",
        "    // ... do other stuff ...\n",
        "\n",
        "    /*\n",
        "     * Next, call a kernel that shows using shared memory\n",
        "     */\n",
        "\n",
        "    // as before, pass in a pointer to data in global memory\n",
        "    use_shared_memory_GPU<<<1, 128>>>(d_arr); \n",
        "    // copy the modified array back to the host\n",
        "    cudaMemcpy((void *)h_arr, (void *)d_arr, sizeof(float) * 128, cudaMemcpyHostToDevice);\n",
        "    // ... do other stuff ...\n",
        "    return 0;\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d9gGNSJwoOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./memory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCiyvyZyfg0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "5bf7afcd-2c4e-4af8-a4ef-555c13dba35b"
      },
      "source": [
        "!nvprof ./memory"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==657== NVPROF is profiling process 657, command: ./memory\n",
            "==657== Profiling application: ./memory\n",
            "==657== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   38.87%  5.0870us         1  5.0870us  5.0870us  5.0870us  use_shared_memory_GPU(float*)\n",
            "                   19.32%  2.5280us         1  2.5280us  2.5280us  2.5280us  use_global_memory_GPU(float*)\n",
            "                   14.66%  1.9190us         1  1.9190us  1.9190us  1.9190us  use_local_memory_GPU(float)\n",
            "                   14.43%  1.8880us         1  1.8880us  1.8880us  1.8880us  [CUDA memcpy HtoD]\n",
            "                   12.72%  1.6640us         1  1.6640us  1.6640us  1.6640us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.70%  233.50ms         3  77.832ms  8.0780us  233.47ms  cudaLaunchKernel\n",
            "                    0.13%  293.73us         1  293.73us  293.73us  293.73us  cudaMalloc\n",
            "                    0.07%  175.00us         1  175.00us  175.00us  175.00us  cuDeviceTotalMem\n",
            "                    0.07%  166.76us        96  1.7370us     136ns  81.198us  cuDeviceGetAttribute\n",
            "                    0.02%  40.351us         3  13.450us  1.8140us  19.374us  cudaMemcpy\n",
            "                    0.01%  24.197us         1  24.197us  24.197us  24.197us  cuDeviceGetName\n",
            "                    0.00%  3.6950us         1  3.6950us  3.6950us  3.6950us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0250us         3     675ns     235ns  1.3990us  cuDeviceGetCount\n",
            "                    0.00%  1.0000us         2     500ns     171ns     829ns  cuDeviceGet\n",
            "                    0.00%     239ns         1     239ns     239ns     239ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yngZiKy-foCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "5f9b32bb-f7c3-4cf4-aacc-32f519ea4206"
      },
      "source": [
        "!nvprof --print-gpu-trace ./memory"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==682== NVPROF is profiling process 682, command: ./memory\n",
            "==682== Profiling application: ./memory\n",
            "==682== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "375.71ms  1.8880us              (1 1 1)       (128 1 1)        16        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  use_local_memory_GPU(float) [106]\n",
            "376.04ms  1.8560us                    -               -         -         -         -      512B  263.08MB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "376.06ms  2.4000us              (1 1 1)       (128 1 1)        16        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  use_global_memory_GPU(float*) [109]\n",
            "376.07ms  1.6320us                    -               -         -         -         -      512B  299.19MB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "376.09ms  5.1520us              (1 1 1)       (128 1 1)        22      512B        0B         -           -           -           -     Tesla T4 (0)         1         7  use_shared_memory_GPU(float*) [111]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCXsvSqnwqm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc -o associative associative.cu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiBjTBSswuwx",
        "colab_type": "code",
        "outputId": "11215822-cb04-4b94-87e7-7dd490f13ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!./associative"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1 + 1e+99) + -1e+99 == 0\n",
            "1 + (1e+99 + -1e+99) == 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBROeYZZwwih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc -o atomics atomics.cu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZbnLYiww2lj",
        "colab_type": "code",
        "outputId": "94d61893-60f8-44db-e9df-a25bc4ac8a61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "!./atomics"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000000 total threads in 1000 blocks writing into 100 array elements\n",
            "{ 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 }\n",
            "Time elapsed = 0.18976 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FANGs9Z2w4MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}