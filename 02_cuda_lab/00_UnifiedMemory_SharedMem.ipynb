{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00_UnifiedMemory_SharedMem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonggunlee/CUDATeaching/blob/master/02_cuda_lab/00_UnifiedMemory_SharedMem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC8OEmdvu52k",
        "colab_type": "text"
      },
      "source": [
        "## Unified Memory Test & Shared Memory vs Global Memory Test\n",
        "\n",
        "# Unified Memory Test\n",
        "\n",
        "참조: https://devblogs.nvidia.com/unified-memory-cuda-beginners/\n",
        "\n",
        "\n",
        "cudaMalloc 및 cudaMemCpy 등에 대한 고려 없이 마치 host에서 메모리를 사용하 듯이 GPU의 메모리를 사용함\n",
        "\n",
        "**cudaMallocManaged** 를 사용합니다!!!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiDceBCqu0TF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d66307b-a3d5-4d75-d0f3-2e09ba18e5fd"
      },
      "source": [
        "%%writefile unifiedMem.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        " \n",
        "// CUDA kernel to add elements of two arrays\n",
        "__global__\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int stride = blockDim.x * gridDim.x;\n",
        "  for (int i = index; i < n; i += stride)\n",
        "    y[i] = x[i] + y[i];\n",
        "}\n",
        " \n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20;\n",
        "  float *x, *y;\n",
        " \n",
        "  // Allocate Unified Memory -- accessible from CPU or GPU\n",
        "  cudaMallocManaged(&x, N*sizeof(float));\n",
        "  cudaMallocManaged(&y, N*sizeof(float));\n",
        " \n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0f;\n",
        "    y[i] = 2.0f;\n",
        "  }\n",
        " \n",
        "  // Launch kernel on 1M elements on the GPU\n",
        "  int blockSize = 256;\n",
        "  int numBlocks = (N + blockSize - 1) / blockSize;\n",
        "  add<<<numBlocks, blockSize>>>(N, x, y);\n",
        " \n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        " \n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        " \n",
        "  // Free memory\n",
        "  cudaFree(x);\n",
        "  cudaFree(y);\n",
        " \n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing unifiedMem.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJuad17dw3i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc -o unifiedMem unifiedMem.cu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g_RA52kw3UX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b981cae8-c5ae-40ba-e462-528b385daebf"
      },
      "source": [
        "!./unifiedMem"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max error: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chCSPzl9xOHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "4e72a62e-8c47-4057-840e-74dfac2e3c1a"
      },
      "source": [
        "!nvprof ./unifiedMem"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==404== NVPROF is profiling process 404, command: ./unifiedMem\n",
            "Max error: 0\n",
            "==404== Profiling application: ./unifiedMem\n",
            "==404== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  102.46us         1  102.46us  102.46us  102.46us  add(int, float*, float*)\n",
            "      API calls:   98.33%  219.67ms         2  109.84ms  803.66us  218.87ms  cudaMallocManaged\n",
            "                    0.83%  1.8441ms         1  1.8441ms  1.8441ms  1.8441ms  cudaLaunchKernel\n",
            "                    0.52%  1.1627ms         2  581.33us  486.14us  676.53us  cudaFree\n",
            "                    0.17%  379.82us        96  3.9560us     157ns  150.05us  cuDeviceGetAttribute\n",
            "                    0.08%  189.25us         1  189.25us  189.25us  189.25us  cuDeviceTotalMem\n",
            "                    0.05%  116.81us         1  116.81us  116.81us  116.81us  cudaDeviceSynchronize\n",
            "                    0.01%  23.703us         1  23.703us  23.703us  23.703us  cuDeviceGetName\n",
            "                    0.00%  3.2300us         1  3.2300us  3.2300us  3.2300us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.1020us         3     700ns     183ns  1.1680us  cuDeviceGetCount\n",
            "                    0.00%  1.6160us         2     808ns     262ns  1.3540us  cuDeviceGet\n",
            "                    0.00%     354ns         1     354ns     354ns     354ns  cuDeviceGetUuid\n",
            "\n",
            "==404== Unified Memory profiling result:\n",
            "Device \"Tesla K80 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "       6  1.3333MB  256.00KB  2.0000MB  8.000000MB  1.184960ms  Host To Device\n",
            "      90  136.53KB  4.0000KB  0.9961MB  12.00000MB  1.893344ms  Device To Host\n",
            "Total CPU Page faults: 45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOB94YC0x8sN",
        "colab_type": "text"
      },
      "source": [
        "- 참조: \n",
        "    - https://devblogs.nvidia.com/unified-memory-cuda-beginners/\n",
        "    - https://devblogs.nvidia.com/maximizing-unified-memory-performance-cuda/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg3EPDZVvGaf",
        "colab_type": "text"
      },
      "source": [
        "#  Shared Memory vs Global Memory Test\n"
      ]
    }
  ]
}